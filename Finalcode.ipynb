{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpD8ZX+SnqWX5UtxI0SG3B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rochitha-prabhuram/Digital-EHR/blob/main/Finalcode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHK9wG9jf2sm",
        "outputId": "d2496520-d3ae-42b5-dfab-6122c17a9b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
            "Fetched 186 kB in 1s (328 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.6/244.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.9/547.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.5/408.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for medspacy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for medspacy_quickumls (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y poppler-utils tesseract-ocr\n",
        "\n",
        "!pip install -q pdf2image pytesseract opencv-python-headless\n",
        "!pip install -q spacy medspacy\n",
        "!pip install -q pandas numpy regex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import json\n",
        "\n",
        "from pdf2image import convert_from_path\n",
        "import spacy\n",
        "import medspacy\n"
      ],
      "metadata": {
        "id": "2Qtv0Qbof3po"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base English NLP - Load without the default parser and NER to avoid conflicts with medspacy's components\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
        "\n",
        "# Medical extensions (rule-based, stable)\n",
        "nlp = medspacy.load(nlp)"
      ],
      "metadata": {
        "id": "TgW2rBlpgMTb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PDF_PATH = /content/Input doc.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "iKXYcDWlgY7N",
        "outputId": "20a1eef6-07a1-47d8-c92d-04382185356f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1774332139.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1774332139.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    PDF_PATH = /content/Input doc.pdf\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6cea9b3"
      },
      "source": [
        "Please upload your `Input doc.pdf` file using the following code cell. Once uploaded, its path in Colab will be `/content/Input doc.pdf`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "6b63da7b",
        "outputId": "dadafeec-987c-41ae-c6e4-c6f52a7cc415"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-436f6992-98ef-49c0-800f-ea02165b10c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-436f6992-98ef-49c0-800f-ea02165b10c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Input doc.pdf to Input doc (1).pdf\n",
            "User uploaded file \"Input doc (1).pdf\" with length 2064696 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a911430"
      },
      "source": [
        "PDF_PATH = \"/content/Input doc (1).pdf\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages = convert_from_path(PDF_PATH, dpi=300)\n",
        "print(f\"Total pages detected: {len(pages)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFMdST0zgoGq",
        "outputId": "f065f365-cf5b-4c11-89f6-44a4e683d8ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pages detected: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(pil_img):\n",
        "    img = np.array(pil_img)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        blur, 255,\n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY, 31, 2\n",
        "    )\n",
        "    return thresh\n"
      ],
      "metadata": {
        "id": "_zGYbGR7gp_a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(img):\n",
        "    data = pytesseract.image_to_data(\n",
        "        img,\n",
        "        output_type=pytesseract.Output.DICT,\n",
        "        config=\"--psm 6\"\n",
        "    )\n",
        "\n",
        "    words = []\n",
        "    for i in range(len(data[\"text\"])):\n",
        "        if int(data[\"conf\"][i]) > 50:\n",
        "            words.append(data[\"text\"][i])\n",
        "\n",
        "    return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "PLO92_g6hTqD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_texts = {}\n",
        "\n",
        "for i, page in enumerate(pages):\n",
        "    processed = preprocess_image(page)\n",
        "    text = extract_text(processed)\n",
        "    page_texts[f\"page_{i+1}\"] = text\n"
      ],
      "metadata": {
        "id": "VwBLC_QthV4d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_page(text):\n",
        "    t = text.lower()\n",
        "    if \"in-patient record\" in t or \"age / sex\" in t:\n",
        "        return \"demographics\"\n",
        "    if \"t.p.r\" in t or \"pulse\" in t:\n",
        "        return \"vitals\"\n",
        "    if \"tab\" in t or \"inj\" in t:\n",
        "        return \"medications\"\n",
        "    if \"investigation\" in t or \"hb\" in t:\n",
        "        return \"labs\"\n",
        "    if \"discharge\" in t or \"summary\" in t:\n",
        "        return \"discharge\"\n",
        "    return \"other\"\n"
      ],
      "metadata": {
        "id": "aB4orMfthXsb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patient_info(text):\n",
        "    data = {}\n",
        "\n",
        "    name = re.search(r\"Name\\s*:\\s*([A-Z ]+)\", text)\n",
        "    age = re.search(r\"Age\\s*/\\s*Sex\\s*:\\s*(\\d+)\", text)\n",
        "    doa = re.search(r\"D\\.O\\.A\\s*:\\s*([\\d/]+)\", text)\n",
        "    diagnosis = re.search(r\"Diagnosis\\s*:\\s*(.+)\", text)\n",
        "\n",
        "    if name:\n",
        "        data[\"name\"] = name.group(1).title()\n",
        "    if age:\n",
        "        data[\"age\"] = int(age.group(1))\n",
        "    if doa:\n",
        "        data[\"date_of_admission\"] = doa.group(1)\n",
        "    if diagnosis:\n",
        "        data[\"diagnosis\"] = diagnosis.group(1).strip()\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "dkLShcsAjlVD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_medical_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = set()\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        entities.add(ent.text)\n",
        "\n",
        "    return list(entities)\n"
      ],
      "metadata": {
        "id": "dAJhNm9vjnhA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = {\n",
        "    \"patient\": {},\n",
        "    \"entities\": [],\n",
        "    \"pages\": []\n",
        "}\n",
        "\n",
        "for page, text in page_texts.items():\n",
        "    category = classify_page(text)\n",
        "\n",
        "    if category == \"demographics\":\n",
        "        output[\"patient\"].update(extract_patient_info(text))\n",
        "\n",
        "    output[\"entities\"].extend(extract_medical_entities(text))\n",
        "    output[\"pages\"].append({\n",
        "        \"page\": page,\n",
        "        \"category\": category\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6yMd0jkjrVv",
        "outputId": "8c93a309-1b05-47d4-cedc-a6d25a13b290"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2026-01-11 05:38:35.622\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=21] [doc 0] Token 0 '&' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.623\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=21] [doc 0] Token 47 '\"' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.624\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=21] [doc 0] Token 47 '\"' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.626\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=21] [doc 0] Token 121 '2' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.627\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=21] [doc 0] Token 121 '2' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.628\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=21] Token/tag mapping: [(&, True), (°, False), (ve, False), (™, False), (‘, False), (a, False), (., False), (., False), (,, False), (:, False), (reg, False), (:, False), (~, False), (:, False), (an, False), (Centre, False), (pa, False), (:, False), (Reed, False), (,, False), (\", False), (ay, False), (64, False), (‘, False), (a, False), (REGISTRATION, False), (aes, False), (4, False), (., False), (_, False), (:, False), (:, False), (., False), (:, False), (|, False), (1, False), (., False), (., False), (., False), (ah, False), (“, False), (a, False), (y, False), (‘, False), (:, False), (\\3, False), (., False), (\", True), (|, False), (1, False), (., False), (., False), (oo, False), (;, False), (>, False), (', False), (i, False), (‘, False), (|, False), (‘, False), (|, False), (q, False), (-, False), (|, False), (Mobile, False), (enate, False), (Numbers, False), (t, False), (‘, False), (i, False), (., False), (|, False), (s, False), (., False), (4, False), (., False), (“, False), (Does, False), (the, False), (‘, False), (No, False), (rt, False), (i, False), (f, False), (a7, False), (-, False), (pee, False), (=, False), (|, False), (i, False), (Number, False), (”, False), (‘, False), (Referred, False), (by, False), (‘, False), (a, False), (., False), (‘, False), (at, False), (ve, False), (ware, False), (i, False), (/, False), (Mobile, False), (Z, False), (i, False), (:, False), (|, False), (|, False), (ai, False), (2, False), (\\, False), (>, False), (., False), (:, False), (‘, False), (Information, False), (Furnished, False), (By, False), (., False), (2, True), (iW, False), (—, False), (:, False), (ae, False), (The, False), (above, False), (Information, False), (Furnished, False), (truc, False), (to, False), (my, False), (knowledge, False), (., False), (:, False), (woe, False), (tet, False), (a, False), (\", False), ((, False), (:, False), (., False), (Date, False), (3, False), (wig, False), (,, False), (-, False), (_, False), (=, False), (-, False), (., False), (|, False), (), False), (_, False), (T, False), (}, False), (:, False), (~, False), (TN, False), (Toa, False), (‘, False), (3, False), (pers, False), (ra, False), (®, False), (,, False), (re, False), (|, False), (ot, False), (|, False), (a, False), (aL, False), (:, False), (4, False), (-, False), (PT, False), (af, False), (3, False), (OST, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.663\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=22] [doc 0] Token 0 '4' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.665\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=22] [doc 0] Token 115 'Am' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.666\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=22] [doc 0] Token 115 'Am' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.668\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=22] Token/tag mapping: [(4, True), (., False), (r, False), (ft, False), (A, False), (fe, False), (:, False), (;, False), (—, False), (:, False), (~, False), (., False), (~, False), (Jt, False), (a, False), (BRJ, False), (Ortho, False), (,, False), (Centre, False), (&, False), (MAK, False), (|, False), (ortho, False), (Bus, False), (Stop, False), (;, False), (Mettupalayam, False), (Road, False), (,, False), (-, False), (|, False), (Coimbatore, False), (tee, False), (=, False), (—, False), (mie, False), (f, False), (:, False), (:, False), (|, False), (|, False), (|, False), (surgical, False), (|, False), (Wi, False), (—, False), (‘, False), (OT, False), (‘, False), (side, False), (nk, False), (=, False), (|, False), (|, False), (We, False), (:, False), (‘, False), (|, False), (!, False), (t, False), (‘, False), (posted, False), (we, False), (|, False), (Blood, False), (Investigations, False), (we, False), (|, False), (1, False), (., False), (r, False), (\\, False), (=, False), (=, False), (—, False), (:, False), (Part, False), (Preparation, False), (;, False), (-, False), (‘, False), (Echo, False), (~, False), (wes, False), (7, False), (., False), (—, False), (|, False), (|, False), (~, False), (~, False), (drugs, False), (2, False), (Peepop, False), (Preop, False), (Antibiotics, False), (Dug, False), (;, False), (dose, False), (71, False), (-, False), (158, False), (\", False), (., False), (a, False), (i., False), (gt, False), (i, False), (—, False), (*, False), (-, False), (4, False), (,, False), (ath, False), (., False), (Am, True), (a, False), (roe, False), (att, False), (LO, False), (Ue, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.720\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=23] [doc 0] Token 0 '.' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=23] [doc 0] Token 135 'drainage' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.722\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=23] [doc 0] Token 135 'drainage' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.723\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=23] [doc 0] Token 188 'J' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.724\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=23] [doc 0] Token 188 'J' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.726\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=23] Token/tag mapping: [(., True), (er, False), (a, False), (., False), (=, False), (—, False), (il, False), (een, False), (a, False), (‘, False), (jo, False), (—, False), (=, False), (~, False), (=, False), (_, False), (om, False), (|, False), (pe, False), (|, False), (-, False), ({, False), (‘, False), (\\, False), (y, False), (i, False), (}, False), (|, False), (4, False), (mee, False), (_, False), (|, False), (if, False), (Summary, False), (Lg, False), (Age, False), (:, False), (MALE, False), (STH, False), (STREET, False), (KALYAN, False), (JEWCLLRES, False), (ROAD, False), (:, False), (MAR, False), (GANOHIPURAM, False), (-, False), (PATIENT, False), (COIMBATORE, False), (01, False), (-, False), (11, False), (-, False), (2025, False), (11, False), (:, False), (68, False), (6438305656, False), (,, False), (6369003702, False), (12, False), (:, False), (88, False), (that, False), (~, False), (URGERY, False), (DATE, False), (Kamalanathan, False), (M.S., False), (,, False), ((, False), (Ortho, False), (), False), (MNAMS, False), (it, False), (ENG, False), (_, False), (Consultant, False), (Orthopaedic, False), (,, False), (Trauma, False), (and, False), (Joint, False), (Replacement, False), (Surgeon, False), (:, False), (th, False), ({, False), (Rahman, False), (\\, False), (mY, False), (Post, False), (Traumatic, False), (Necrotizing, False), (Fascitis, False), (., False), (\\, False), (4, False), (Debridement, False), (Right, False), (Leg, False), (:, False), (‘, False), (with, False), (Right, False), (|, False), (Clo, False), (:, False), (:, False), (CHIEF, False), (:, False), (|, False), (MrRamesh, False), (old, False), (‘, False), (male, False), (:, False), (admitted, False), (with, False), (Right, False), (initially, False), (‘, False), (swelling, False), (was, False), (present, False), (over, False), (Rightleg, False), (which, False), (ag, False), (by, False), (“, False), (hospital, False), (Incision, False), (and, False), (., False), (drainage, True), (:, False), (done, False), (;, False), (Patient, False), (now, False), (came, False), (for, False), (4, False), (|, False), (., False), (“, False), (debridement, False), (under, False), (anaesthesia, False), (., False), (~, False), (T, False), (i, False), (ve, False), (Di, False), (:, False), (Nota, False), (known, False), (case, False), (of, False), (i, False), (\", False), (., False), (rut, False), (riented, False), (/, False), (afebrile, False), (:, False), (‘, False), (pn, False), (EXAMINATION, False), (,, False), (Patient, False), (conscious, False), (/, False), (|, False), (\\, False), (min, False), (2, False), (+, False), (ros, False), ((, False), (., False), (4, False), (|, False), (NEND, False), (., False), (J, True), (}, False), (em, False), (=, False), (°, False), (2, False), (1, False), (}, False), (., False), (., False), (a, False), (., False), (., False), (|, False), (wt, False), (-, False), (3, False), (~, False), (a, False), (=, False), (ta, False), (FF, False), (MS, False), (oo, False), (wea, False), (,, False), (|, False), (rok, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.776\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=24] [doc 0] Token 0 'ge' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.777\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=24] [doc 0] Token 103 'ii' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.778\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=24] [doc 0] Token 103 'ii' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.780\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=24] [doc 0] Token 175 'ad' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.782\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=24] [doc 0] Token 175 'ad' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.784\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=24] Token/tag mapping: [(ge, True), (Te, False), (-, False), (-, False), (‘, False), (—, False), (=, False), (4, False), (1, False), (\\, False), (., False), (., False), (‘, False), (J, False), (¢, False), (ds, False), (}, False), (\\, False), (., False), ($, False), (R, False), (~, False), (l, False), (‘, False), (rt, False), (“, False), (ON, False), (-, False), (©, False), (Distay, False), (Activa, False), (toa, False), (Movements, False), (', False), (+, False), (|, False), (=, False), (WESTISATIONS, False), (Lab, False), (-, False), (_, False), (=, False), (‘, False), (k, False), (ZS, False), (|, False), (Urider, False), (wi, False), (the, False), (patient, False), (tn, False), (PROCEDURE, False), (:, False), (necrotizing, False), (fascitis, False), (Wound, False), (of, False), (10x, False), (5, False), (“, False), (sin, False), (Right, False), (8A, False), (Infected, False), (lissues, False), (a, False), (applied, False), (Culture, False), (and, False), (|, False), (>, False), (Lee, False), (—, False), (COURSE, False), (McRamesh, False), (43, False), (year, False), (old, False), (mate, False), (patient, False), (was, False), (‘, False), (tH, False), (Right, False), (Major, False), (,, False), (Kamalanathan, False), (consultant, False), (Orthopa, False), (10, False), (nett, False), (:, False), (t, False), (su, False), (t, False), (:, False), (Replacement, False), (as, False), (\", False), (Wo, False), (PO, False), (Measures, False), (., False), (ii, True), (b, False), (ids, False), (done, False), (On, False), (:, False), (\\, False), (rand, False), (discharged, False), (with, False), (following, False), (advices, False), (i, False), (condition, False), (imptoved, False), (an, False), (c, False), (., False), (tre, False), (-, False), (om, False), (., False), (I., False), (7, False), (\", False), (-, False), (DISCHARGE, False), (days, False), (:, False), (Ce, False), (|, False), (Tab, False), (., False), (|, False), (4, False), (odol, False), (|, False), (|, False), (1, False), (Kamalanath, False), (ay, False), (complain, False), (=, False), (be, False), (=, False), (., False), (REVIEW, False), (:, False), (=, False), (., False), (1, False), (g, False), (ae, False), (=, False), (-, False), (‘, False), (EN, False), (Company, False), (2, False), (at, False), (‘, False), (-, False), (-, False), (-, False), (., False), (-, False), (., False), (f, False), (~, False), (., False), (_, False), (., False), (ad, True), (., False), (., False), (te, False), (., False), (a, False), (c, False), (=, False), (-, False), (:, False), (=, False), (>, False), (Ge, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=25] [doc 0] Token 0 'te' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.819\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=25] [doc 0] Token 3 'i' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=25] [doc 0] Token 3 'i' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.821\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=25] [doc 0] Token 145 '—' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.823\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=25] Token/tag mapping: [(te, True), (me, False), (., False), (i, True), (., False), (., False), (~, False), (:, False), (ete, False), (=, False), (\\, False), (~, False), (=, False), ({, False), (1, False), (aN, False), (i, False), (!, False), (-, False), (—, False), (lA, False), (=, False), (4S, False), (., False), (oS, False), (ae, False), (Taw, False), (', False), (:, False), (:, False), (Cc, False), (|, False), (ay, False), (|, False), (ANN, False), (i, False), (SS, False), (~, False), (—, False), (., False), (!, False), (ie, False), (=, False), (=, False), (=, False), (=, False), (|, False), (i, False), (}, False), (=, False), (at, False), (i, False), (_, False), (-, False), (ry, False), (:, False), (:, False), (., False), (“, False), (AY, False), (BR, False), (\\, False), (EEE, False), (FEE, False), (=, False), (=, False), (=, False), (b, False), (5, False), (or, False), (9, False), (EEE, False), (PEER, False), (Bel, False), (5, False), (Sos, False), (=|, False), (‘, False), (le, False), (:, False), (=], False), (>, False), (}, False), (=, False), (°, False), (BEE, False), (=, False), (=, False), (eS, False), (:, False), (7, False), (|, False), (EY, False), (EER, False), (;, False), (a, False), (=], False), (i, False), (=, False), (t, False), (Z, False), (UB, False), (=, False), (|, False), (., False), (ae, False), (“, False), (he, False), (295, False), (=, False), (}, False), (=, False), (=, False), (., False), (a, False), (“, False), (a, False), (EES, False), (=, False), (—, False), (ab, False), (=], False), (EH, False), (a, False), (—, False), (-, False), (EE, False), (i, False), (36, False), (., False), (:, False), (=, False), (=, False), (=, False), (1, False), (=, False), (=, False), (“, False), (-, False), (ae, False), (—, False), (—, False), (1, False), (-, False), (:0, False), (—, True)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.857\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=26] [doc 0] Token 0 'Te' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=26] [doc 0] Token 126 '|' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.859\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=26] [doc 0] Token 126 '|' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.860\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=26] [doc 0] Token 145 '—' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.862\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=26] Token/tag mapping: [(Te, True), (:, False), (7, False), (NA, False), (Ortho, False), (-, False), (Centre, False), (&, False), (-BRJ, False), (:, False), (pln, False), (,, False), (l, False), (5, False), (—, False), (7, False), (BR, False), (Y, False), (Mettupalayam, False), (Road, False), (), False), (Rs, False), (|, False), (|, False), (|, False), (gs, False), (sp, False), (pel, False), (|, False), (MAK, False), (cut, False), (on, False), (., False), (ross, False), (ye, False), (page, False), (?, False), (., False), (T, False), (1, False), (L, False), (., False), (|, False), (|, False), (-, False), (:, False), (©, False), (1, False), (,, False), (pee, False), (-, False), (:, False), (-, False), (:, False), (|, False), (te, False), (,, False), (=, False), (~, False), (_, False), (|, False), (., False), (1, False), (|, False), (7, False), (-, False), (-, False), (., False), (=, False), (=, False), (_, False), (:, False), (., False), (-, False), (ow, False), (a, False), (‘, False), (=, False), (:, False), (‘, False), (., False), (‘, False), (yes, False), (7, False), (ves, False), (ye, False), (1, False), (_, False), (I, False), (i, False), (|, False), (al, False), (—, False), (po, False), (ph, False), (-, False), (_, False), (=, False), (|, False), (}, False), (5, False), (ee, False), (\\, False), (~, False), (|, False), (|, False), (‘, False), (=, False), (ea, False), (=, False), (4, False), (\\, False), (|, False), (O, False), (-, False), (pe, False), (‘, False), (5, False), (ou, False), (., False), (i, False), (., False), (NG, False), (la, False), (A, False), (I., False), (|, True), (‘, False), (\", False), (=, False), (ma, False), (“, False), (oO, False), (4, False), (f, False), (|, False), (=, False), (:, False), (4, False), (1, False), (-, False), (iF, False), (,, False), (ba, False), (], False), (—, True), (—, False), (—, False), (:, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.894\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=27] [doc 0] Token 0 '\\' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.895\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=27] Token/tag mapping: [(\\, True), (aa, False), (“, False), (*, False), (i, False), (|, False), (_, False), (., False), (=, False), (., False), (oh, False), (ae, False), («, False), (BR, False), (Ortho, False), (Centre, False), (bac, False), (,, False), (il, False), (., False), (wa, False), (wet, False), (., False), (-, False), (—, False), (see, False), (4, False), (—, False), (toy, False), (a, False), (\\, False), (we, False), (A, False), (-, False), (™, False), (|, False), (i, False), (Te, False), (”, False), (wh, False), (j, False), (‘, False), (a, False), (a, False), (*, False), (Ry, False), (4, False), (A, False), (4, False), (-, False), (4, False), (—, False), (pa, False), (a., False), (1, False), (|, False), (|, False), (77, False), (ok, False), (S, False), (1, False), (., False), (1, False), (y, False), (~, False), (_, False), (—, False), (—, False), (—, False), (i, False), (d, False), (1, False), (i, False), (—, False), (—, False), ({, False), (old, False), (:, False), (—, False), (—, False), (mor, False), (iv, False), (Sy, False), (|, False), (=, False), (=, False), (), False), (tha, False), (DA, False), (x, False), (1, False), (73S, False), (!, False), (|, False), (at, False), (oe, False), (-, False), (4, False), (2, False), (re, False), (4, False), (la, False), (i, False), (i, False), (TN, False), (LK, False), (de, False), (|, False), (Ty, False), (Tj, False), (|, False), (|, False), (—, False), (—, False), (4, False), (2, False), (1, False), (4, False), (a, False), (pr, False), (‘, False), (om, False), (=, False), (., False), (i, False), (7, False), (_, False), (:, False), (7, False), (:, False), (ate, False), (ail, False), (., False), (2, False), (a, False), (., False), (7, False), (,, False), (=, False), (“, False), (ee, False), (1, False), (|, False), (WR, False), (2, False), (7, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.939\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=28] [doc 0] Token 0 '‘' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.940\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=28] Token/tag mapping: [(‘, True), (a, False), (=, False), (~, False), (*, False), (he, False), (men, False), (?, False), (., False), (iN, False), (Mul, False), (~, False), (0429, False), (pec, False), (i, False), (‘, False), (gp, False), (“, False), (Bn, False), (”, False), (Cary, False), (Netter, False), (97479, False), (22000, False), (,, False), (|, False), (—, False), (MENT, False), (i, False), (FILLED, False), (CASE, False), ({, False), (CS, False), (Rey, False), (NY, False), (bug, False), (EET, False), (—, False), (=, False), (a, False), (™, False), (du, False), (|, False), (wet, False), (ratio, False), (|, False), (‘, False), (Sig, False), (Clo, False), (@, False), (), False), (presenting, False), (fy, False), (PR, False), (rome, False), (by, False), (wells, False), (ay, False), (\\, False), (wy, False), (4, False), (Significant, False), (Past, False), (illness, False), ((, False), (Medical, False), (wt, False), (|, False), (Urgical, False), (), False), (durations, False), (if, False), (Other, False), (medical, False), (‘, False), (PD, False), (es, False), (Mellitus, False), (—, False), (., False), (‘, False), (on, False), (=, False), (artery, False), (disease, False), (—, False), (:, False), (a, False), (>, False), (|, False), (i, False), (}, False), (History, False), (,, False), (|, False), (|, False), (fh, False), (A, False), (., False), (|, False), (Curent, False), (medications, False), (Ee, False), (ed, False), (Current, False), (medications, False), (&, False), (duration, False), (=, False), (pe, False), (r, False), (>, False), (=, False), (\", False), (i, False), (t, False), (ff, False), (:, False), (=, False), (—, False), (Dif, False), (=, False), (=, False), (r, False), (—, False), (—, False), (-, False), (|, False), (By, False), (family, False), (=, False), (=, False), ([, False), (Hearing, False), (+, False), ({, False), (2, False), (|, False), (ee, False), (et, False), (impairment, False), (:, False), (—, False), (ne, False), (ignificant, False), (Family, False), (History, False), (fis, False), (Significant, False), (Fan, False), (—, False), (I, False), (,, False), (-, False), (_, False), (©, False), (‘, False), (if, False), (for, False), (Gynace, False), ((, False), (or, False), (HSS, False), (mud, False), (St., False), (>, False), (SE, False), (—, False), (History, False), (Lot, False), (x, False), (We, False), (tay, False), (}, False), (a, False), (4, False), (*, False), (ie, False), (a7, False), (4, False), (-¢, False), (Mae, False), (\\, False), (ay, False), (—, False), (a, False), (=, False), (~, False), (|, False), (ey, False), (:, False), (>, False), (., False), (+, False), (,, False), (fos, False), (|, False), (=, False), (., False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 0 '7' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 8 ':' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 8 ':' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.998\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 28 'Oy' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:35.999\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 28 'Oy' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.000\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 39 'a' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 39 'a' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.005\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 57 '-' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.007\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 57 '-' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.007\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 64 '2' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.011\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 64 '2' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.011\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 101 't' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.013\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 101 't' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.015\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] [doc 0] Token 166 '.' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.018\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=29] Token/tag mapping: [(7, True), (~, False), (., False), (=, False), (ha, False), (:, False), (7, False), (., False), (:, True), (a, False), (:, False), (~, False), (a, False), (WAR, False), (BUN, False), (Weight, False), (:, False), (AN, False), (|, False), (4, False), (Ortho, False), (., False), (1, False), (!, False), (te, False), ((, False), (=), False), (!, False), (Oy, True), (‘, False), (., False), (,, False), (aly, False), (a, False), (_, False), (—, False), (“, False), (ly, False), (., False), (a, True), (‘, False), (i, False), (!, False), (ay, False), (4, False), (-, False), (RS, False), (ON, False), (:, False), (we, False), ({, False), (4, False), (Wad, False), (1, False), (|, False), (qd, False), (., False), (-, True), ({, False), ([, False), (|, False), (=, False), (j, False), (., False), (2, True), (., False), (Z, False), (‘, False), ((, False), (:, False), (4, False), (., False), (Lt, False), (Th, False), (i, False), (|, False), (|, False), (|, False), (“, False), (Syste, False), (., False), (be, False), (', False), (1, False), (-, False), (Wes, False), (tas, False), (‘, False), (Bi, False), (TRAUMATIC, False), (:, False), (pp, False), (~, False), (—, False), (=, False), (ce, False), (_, False), (|, False), (Dov, False), (xv, False), (., False), (t, True), (-, False), (?, False), (=, False), (., False), (=, False), (a, False), (~, False), (wy, False), (‘, False), (Lg, False), (~, False), (., False), (-, False), (|, False), (|, False), (—, False), (-, False), (-, False), (:, False), (‘, False), (4, False), (we, False), (Se, False), (oe, False), (-, False), (-, False), (ce, False), (pe, False), (,, False), (7, False), (:, False), (sy, False), (,, False), (fog, False), (=, False), (le, False), (—, False), (&, False), (>, False), (N, False), ((, False), (rl, False), (ysl, False), (tio, False), (}, False), (Resice, False), (cer, False), (., False), (‘, False), (a, False), (=, False), (~, False), (—, False), (et, False), (‘, False), (—, False), (-, False), (ar, False), (a, False), (., False), (-, False), (ta, False), (ot, False), (f., False), (., True), (=, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.076\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=30] [doc 0] Token 0 '-' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=30] [doc 0] Token 158 '~' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.079\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=30] Token/tag mapping: [(-, True), (~, False), (~, False), (=, False), (—, False), (7, False), (_, False), (-, False), (i, False), (‘, False), (Mal, False), (:, False), (Onn, False), (., False), (|, False), (&, False), (MAK, False), (7, False), (], False), («, False), (., False), (*, False), (Phone, False), (1.0422, False), (2433, False), (feltupatayam, False), (Koad, False), (,, False), (PAN, False), (., False), (i, False), (r, False), (bi, False), (}, False), (:, False), (301, False), (/, False), (.2433302, False), (/, False), (2433306, False), (), False), (a, False), (,, False), (Off, False), (04, False), (), False), (“, False), (MAK, False), (97879, False), (22000, False), (,, False), (a, False), (REC, False), (., False), (-, False), (ton, False), (,, False), (=, False), (PN, False), (4, False), (=, False), (4, False), (XQ, False), (|, False), (&, False), (“, False), (|, False), (‘, False), (Pre, False), (., False), (et, False), (2, False), (re, False), (‘, False), (|, False), (|, False), (WY, False), (we, False), (ED, False), (), False), (:, False), (|, False), (4, False), (|, False), (pis, False), (a, False), (\\, False), (fo, False), (5, False), (ase, False), (|, False), (io, False), (FR, False), (., False), (ofp, False), ([, False), (\\, False), (ar, False), (fl, False), (®, False), (Bestel, False), (pp, False), (., False), (., False), (O, False), ('S, False), (|, False), (Officer, False), (], False), (-, False), (|, False), (', False), (m, False), (!, False), (af, False), (°, False), (on, False), (ett, False), (I, False), (ipo, False), (-, False), (‘, False), (i, False), (i, False), (;, False), (=, False), (—, False), (—, False), (q, False), (a., False), ([, False), (-, False), (le, False), (Sh, False), (., False), (pe, False), (., False), (:, False), (|, False), (Mec, False), (of, False), (As, False), (Ok, False), (i, False), (~, False), (°, False), (:, False), (4, False), (-, False), (‘, False), (GZ, False), (—, False), (—, False), (-, False), (:, False), (7, False), (=, False), (Tee, False), (~, True)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.156\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 0 '@' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.159\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 20 '“' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] GAP DETECTED: tokens 20-20 (idx 47-47) between spans 46-48\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 20 '“' marked as sentence start (first token in gap between spans)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.167\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 21 'a' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 75 'SNS' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 75 'SNS' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.175\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 93 'Increasing' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.177\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 93 'Increasing' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.178\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 103 '«' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.179\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] GAP DETECTED: tokens 103-103 (idx 285-285) between spans 284-287\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.181\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 103 '«' marked as sentence start (first token in gap between spans)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.181\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 104 '\"' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.182\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 118 's' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.183\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 118 's' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.183\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 144 'Ie' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 144 'Ie' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 154 'Is' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.188\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 154 'Is' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 159 'Yes' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 159 'Yes' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 179 'No' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.191\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] [doc 0] Token 179 'No' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.192\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=31] Token/tag mapping: [(@, True), (*, False), (1, False), (!, False), (ih, False), (., False), (~, False), (=, False), (“, False), (., False), (., False), (fas, False), (i, False), (gf, False), (Wy, False), (Bers, False), (., False), (., False), (yo, False), (., False), (“, True), (a, True), (a, False), (oF, False), (DAILY, False), (wo, False), (d, False), (cm, False), (., False), (tr, False), (\\, False), (we, False), (rit, False), (., False), (inte, False), (., False), (—, False), (—, False), (“, False), (\\, False), (1, False), (6, False), (Qi, False), (7, False), (:, False), (a, False), (2, False), (None, False), (brought, False), (to, False), (“, False), (8, False), (‘, False), (-, False), (-, False), (., False), (of, False), (*, False), (pAIN, False), (ASSESSMENT, False), (S, False), ((, False), (ww, False), (., False), (7, False), (.., False), (a, False), (\\, False), (Se, False), (Ce, False), (xD, False), (;, False), (By, False), (rt, False), (., False), (SNS, True), (Serfous, False), (Paln, False), (gee, False), (EN, False), (., False), (‘, False), (i., False), (un, False), (r, False), (Vey, False), (1, False), (4, False), (., False), (-, False), (>, False), (2, False), (., False), (Increasing, True), (ge, False), (=, False), (=, False), (|, False), (|, False), (;, False), (\", False), (disorder, False), (., False), («, True), (\", True), (yy, False), (., False), (}, False), (|, False), (i, False), (XN, False), (LSTATUS, False), (1, False), (|, False), (NUTRITIONA, False), (:, False), (Moderate, False), (., False), (s, True), (ood, False), (1, False), (\\od, False), (', False), (}, False), (‘, False), (pial, False), (1, False), (feo, False), (|, False), (., False), (NURSINGNEEDS, False), (:, False), (1, False), (l., False), ({, False), (., False), (problem, False), (VY, False), (2, False), (=, False), (>, False), (i, False), (3, False), (., False), (Ie, True), (the, False), (patient, False), (for, False), (needed, False), (S, False), ([, False), (NO, False), (4, False), (., False), (Is, True), (dependent, False), (to, False), (ADL, False), (?, False), (Yes, True), (needed, False), ({, False), (., False), (Does, False), (paticnt, False), (:, False), (&, False), (Does, False), (have, False), (a, False), (tracheostomy, False), (?, False), (., False), (needed, False), (:, False), (&, False), (the, False), (pain, False), (?, False), (No, True), (Action, False), (needed, False), (patient, False), (at, False), (risk, False), (for, False), (pressure, False), (needed, False), (tg, False), (—, False), (needed, False), (:, False), (Does, False), (the, False), (Patent, False), (have, False), (acl, False), (~, False), (:, False), (., False), (|, False), (|, False), (M, False), (|, False), (a, False), (~, False), (-, False), (at, False), (—, False), (., False), (~, False), (., False), (oe, False), (r, False), (-, False), (4, False), (., False), (a, False), (a, False), (7, False), ({, False), (PES, False), (be, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.234\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=32] [doc 0] Token 0 '.' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.236\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=32] Token/tag mapping: [(., True), (1, False), (\\, False), (ag, False), (!, False), (—, False), (—, False), (,, False), (=, False), (., False), (=, False), (¢, False), (‘, False), (,, False), (‘, False), (Pdi, False), ((, False), (J, False), (., False), (E, False), (x, False), (—, False), (\\, False), (x, False), (“, False), (3, False), (=, False), (fy, False), (\", False), (38, False), (:, False), (3, False), (., False), (2, False), (oe, False), (g, False), (8, False), (‘, False), (fo, False), (., False), (3, False), (5, False), (-, False), (sai, False), (we, False), (RE, False), (ay, False), (Rs, False), (a, False), (”, False), (icf, False), (AY, False), (..., False), (1, False), (:, False), (bal, False), (., False), (+, False), (‘, False), (~, False), (|, False), (=, False), (re, False), (a, False), (ed, False), (&, False), (A, False), (’, False), (q., False), (§, False), (:, False), (5, False), (\\, False), (=, False), (“, False), (A, False), (2, False), (4, False), (j, False), (|, False), (|, False), (°, False), (zi, False), (i, False), (@, False), (ts, False), (‘, False), (f, False), (A, False), (-, False), (=, False), (j, False), (|, False), (1, False), (4, False), (-, False), (|, False), (*, False), (., False), (a, False), (©, False), (|, False), (-, False), (=, False), (‘, False), (|, False), (|, False), (', False), (<, False), (., False), (=, False), (=, False), (!, False), (., False), (=, False), (AQ, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.278\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=33] [doc 0] Token 0 '—' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.281\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=33] [doc 0] Token 77 ':' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.285\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=33] Token/tag mapping: [(—, True), (i, False), (m, False), (oy, False), (Tikes, False), (f, False), (tech, False), (:, False), (., False), (!, False), (fire, False), (:, False), (it, False), (“, False), (ya, False), (a, False), (|, False), (dele, False), (|, False), (Salad, False), (oN, False), (Oy, False), (\", False), (-, False), (pg, False), (Sl, False), (\\, False), (play, False), (rei, False), (., False), (|, False), (:, False), (}, False), (,, False), (2, False), (:, False), (+, False), (~, False), (5, False), (“, False), (4, False), (a, False), (Ser, False), (,, False), (PEL, False), (tee, False), (:, False), (PO, False), (Ta, False), (AY, False), (pk, False), (8, False), (BS, False), (Y, False), (‘, False), (Leg, False), (=, False), (‘, False), (at, False), (:, False), (Te, False), (|, False), (Me, False), (\\, False), (\\, False), (7, False), (=, False), (uf, False), (st, False), (8, False), (., False), (\\, False), (|, False), (2, False), (2, False), (|, False), (a, False), (:, True), (=, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.359\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=34] [doc 0] Token 0 'he' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.364\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=34] [doc 0] Token 145 'Bl' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.365\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=34] [doc 0] Token 145 'Bl' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.366\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=34] [doc 0] Token 222 '|' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.369\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=34] [doc 0] Token 222 '|' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.370\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=34] [doc 0] Token 247 ':' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.371\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=34] Token/tag mapping: [(he, True), (|, False), (An, False), (1, False), (|, False), (par, False), (\", False), (,, False), (wee, False), (., False), (“, False), (uk, False), (us, False), (al, False), (7, False), ([, False), ({, False), (., False), (a, False), (), False), (4, False), (7, False), (i, False), (4, False), (Cen, False), (N, False), (tee, False), (ye, False), (ROS, False), (Bes, False), (—, False), (A, False), (~, False), (., False), (a, False), (-, False), (—, False), (af, False), (,, False), (Ve, False), (ys, False), (3, False), (*, False), (4, False), (|, False), (HO, False), (}, False), (Sg, False), (ak, False), (“, False), (AGE, False), (‘, False), (K, False), (“, False), (3, False), (OF, False), (AN, False), (3, False), (IME, False), (4, False), (js, False), (., False), (4a, False), (., False), ({, False), (DATE, False), (&, False), (TIME, False), (OF, False), (PE, False), (OF, False), (4, False), (a, False), (OF, False), (', False), (St, False), (mo, False), (a, False), ((, False), (DATE, False), (OF, False), (S, False), (', False), (rr, False), (CORING, False), (eg, False), (SCORIN, False), (ay, False), (~, False), (1, False), (., False), (ray, False), (,, False), (Aye, False), (aye, False), (4, False), (§, False), (rT, False), (ae, False), (J, False), (A, False), (TI, False), (_, False), (=, False), (i, False), (<, False), (rT, False), (=, False), (ay, False), (7, False), (an, False), (an, False), (Us, False), (:, False), (6, False), (], False), (3, False), (8, False), (ag, False), (:, False), (ry, False), (TT, False), (Ap, False), (\\, False), (Bg, False), (., False), (nn, False), (=, False), (|, False), (|, False), (TT, False), (OH, False), (:, False), (', False), (Weg, False), (‘, False), (3.0, False), (=, False), (., False), (it, False), (BP, False), (=, False), (“, False), (abe, False), (., False), (Bl, True), (|, False), (-9, False), (Fu, False), (|, False), ((, False), (j, False), (¢, False), (|, False), (., False), (of, False), (=, False), (9, False), (., False), (Ne, False), (toy, False), (3, False), (“, False), (at, False), (=, False), (6, False), (with, False), (Pal, False), (with, False), (ain, False), (3, False), (:, False), (7, False), (4, False), (=, False), (Pra, False), (:, False), (“, False), (SRS, False), (Bion, False), (:, False), (=, False), (4, False), (|, False), (pe, False), (‘, False), (J, False), (Surgicat, False), (Me, False), (O, False), (=, False), (Se, False), (i, False), (}, False), (required, False), (a, False), (|, False), (|, False), (Sey, False), (i, False), (:, False), (4, False), (“, False), (ep, False), (:, False), (—, False), (a, False), (a, False), (4, False), (™, False), (Tho, False), (—, False), (core, False), (:, False), (an, False), (a, False), (io, False), (8, False), (., False), (a, False), (ites, False), (., False), (|, True), (2, False), (:, False), (foo, False), (8, False), (eg, False), (:, False), (mt, False), (=, False), (:, False), (oO, False), (., False), (&, False), (A, False), (OR, False), (-, False), (=, False), (,, False), (., False), (ws, False), (_, False), (>, False), (,, False), (“, False), (Fz, False), (:, True)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.458\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=35] [doc 0] Token 0 'wey' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.462\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=35] [doc 0] Token 52 'Hosp' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.463\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=35] [doc 0] Token 52 'Hosp' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.464\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=35] [doc 0] Token 180 '—' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.467\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=35] Token/tag mapping: [(wey, True), (3, False), (4, False), (a, False), (:, False), (C, False), (~, False), (gn, False), (., False), (., False), ({, False), (>, False), (ty, False), (—, False), (,, False), (~, False), (}, False), (:, False), (Centre, False), (S, False), (:, False), (MAK, False), (Hospital, False), (x, False), ((, False), (Surgical, False), (Superspectalty, False), (Hospital, False), (), False), (|, False), (Company, False), (Stop, False), (,, False), (Mattupalayam, False), (Road, False), (,, False), (Colmbatore, False), (/, False), (|, False), (Phome, False), (’, False), (,, False), (0422, False), (¢, False), (2439301, False), (,, False), (2499302, False), (/, False), (97869, False), (22009, False), (Ital, False), (., False), (Hosp, True), (=, False), (?, False), (_, False), (., False), (ANESTHESIA, False), (RECOVERY, False), (SCORE, False), (4, False), (ap, False), (|, False), (:, False), (TIME, False), (OF, False), (8, False), (°, False), (t, False), (SIA, False), (., False), (:, False), (|, False), (—, False), (|, False), (/, False), (8, False), ((, False), (UATE, False), (OF, False), (SCORING, False), (=, False), (i, False), (—, False), (.., False), (=, False), (7, False), (is, False), (=, False), (Ha, False), (=, False), (=, False), (—, False), (|, False), (any, False), (|, False), (Unable, False), (|, False), (breath, False), (deeply, False), (and, False), (cough, False), (=, False), (Dyspnea, False), (or, False), (fimited, False), (-, False), (0, False), (=, False), (or, False), (unable, False), (to, False), (‘, False), (2, False), (=, False), (are, False), (=, False), (=, False), (ot, False), (pre, False), (=, False), (gp, False), (of, False), (Pre, False), (anesthetic, False), (-, False), (-, False), (-, False), (-, False), (ler, False), (to, False), (on, False), (=, False), (\", False), (3, False), (=, False), (supplementary, False), (02, False), (-, False), (., False), (ma, False), (despite, False), (pit, False), (hee, False), (fe, False), (Soakage, False), (dose, False), (dressing, False), (ye, False), (|, False), (Moderate, False), (up, False), (dressing, False), (Seveie, False), (/mote, False), (dressing, False), (Pe, False), (severe, False), (?, False), (eh, False), (at, False), (fi, False), (Score, False), (of, False), (—, False), (can, False), (be, False), (considerable, False), (for, False), (Score, False), (?, False), (with, False), (9, False), (of, False), (higher, False), (can, False), (be, False), (|, False), (|, False), (_, False), (—, True)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.520\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=36] [doc 0] Token 0 '4' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.521\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=36] [doc 0] Token 81 '0' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.522\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=36] [doc 0] Token 81 '0' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.526\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=36] Token/tag mapping: [(4, True), (:, False), (>, False), (a, False), (j, False), (~, False), (Me, False), (ia, False), (=, False), (i, False), (2S, False), (|, False), (ge, False), (o, False), (‘, False), (BE, False), (=), False), (oR., False), (|, False), (a, False), (2, False), (., False), (62, False), (if, False), (OA, False), (oe, False), (:, False), (int, False), (wr, False), (3, False), (ORT, False), (2, False), (., False), (i, False), (\\, False), (\\, False), (1, False), (we, False), (:, False), (<, False), (,, False), (x, False), (OT, False), (Mer, False), (4, False), (al, False), (So, False), (|, False), (|, False), (!, False), (fa, False), (], False), ({, False), (a, False), (fe, False), (:, False), ({, False), (a, False), (5, False), (Ss, False), (232, False), (i, False), (yoy, False), (|S, False), (oS., False), (te, False), (?, False), (io, False), (S, False), (Peed, False), (og, False), (:, False), (peas, False), (a, False), (ELE, False), (S, False), (|, False), (}, False), (che, False), (wl, False), (., False), (0, True), (=, False), (at, False), (LO, False), (,, False), (!, False), (‘, False), (a, False), (ee, False), (:, False), (‘, False), ({, False), (is, False), (., False), (‘, False), (., False), (ey, False), (we, False), (abe, False), (=, False), (|, False), (., False), (ta, False), (WL, False), (|, False), (“, False), (Ve, False), (PE, False), (ig, False), (CBA, False), (Ps, False), (oa, False), (PEP, False), (=, False), (—, False), (<, False), (., False), (ZF, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=37] [doc 0] Token 0 '=' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.603\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=37] [doc 0] Token 31 'Pe' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.604\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=37] [doc 0] Token 31 'Pe' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.609\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=37] [doc 0] Token 98 '&' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.612\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=37] [doc 0] Token 98 '&' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.618\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=37] Token/tag mapping: [(=, True), (., False), (8, False), (gs, False), (5, False), (2, False), (., False), (1, False), (ss, False), (8, False), (., False), (i, False), (i, False), (~, False), (}, False), (_, False), (a, False), (,, False), (te, False), (if, False), (1, False), (SP, False), (8, False), (3D, False), (,, False), (i, False), ((, False), (OO, False), (ta, False), (aa, False), (!, False), (Pe, True), (4, False), (:, False), (ve, False), (:, False), (wR, False), (:, False), (2, False), (Oo, False), (Vo, False), (pe, False), (42272, False), (E, False), (gs, False), (., False), (., False), (¥, False), (:, False), (‘, False), (Bi, False), (:, False), (=|, False), (., False), (6, False), (;, False), (3, False), (8, False), (2, False), (ig, False), (ge, False), (|, False), (=, False), (£, False), (93, False), (=, False), ((, False), (Ee, False), (|, False), (:, False), (+, False), (Es, False), (-, False), (£, False), (22, False), (), False), (Hi, False), (2, False), (/, False), (tgs, False), (pre, False), (., False), (1, False), (@, False), (i, False), (Pa, False), (a, False), (53, False), (2, False), (on, False), (a, False), (-a, False), (@, False), (-, False), (V2, False), (“, False), (3, False), (., False), (&, True), (:, False), (|, False), (=, False), (2, False), (\\, False), (Bee, False), (:, False), (iB, False), (UB, False), (Ags, False), (SUR, False), (gg, False), (TAL, False), (Pu, False), (N, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.658\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=38] [doc 0] Token 0 'wee' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.662\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=38] [doc 0] Token 77 '-' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.663\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=38] Token/tag mapping: [(wee, True), (_, False), (we, False), (=, False), (TB, False), (N, False), (at, False), (A., False), (Al, False), (‘, False), (fe, False), (|, False), (&, False), (Be, False), («, False), (i, False), (d, False), (:, False), (213, False), (3, False), (lal, False), (,, False), ({, False), (Se, False), (NES, False), (~, False), (|, False), (is, False), (4, False), (“, False), (4, False), (%, False), (4, False), (‘, False), (3, False), (:, False), (=, False), (St, False), (|, False), (i, False), (213, False), (4, False), (Sy, False), (Wy, False), (i, False), (gq, False), (|, False), (\\, False), (a3, False), (I, False), (es, False), (., False), (|, False), (g, False), (a, False), (a4, False), (i, False), (7, False), (i, False), (=, False), (=, False), (5, False), (4, False), (‘, False), (3, False), (|, False), (1, False), (}, False), (:, False), (—, False), (—, False), (af, False), (=, False), (=, False), (~, False), (=, False), (., False), (-, True)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.688\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=39] [doc 0] Token 0 'ke' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.690\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=39] [doc 0] Token 41 '|' marked as sentence start (span end next token)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.692\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=39] Token/tag mapping: [(ke, True), (=, False), (., False), (any, False), (-, False), (ets, False), (a, False), (-, False), (_, False), (os, False), (7, False), (Contre, False), (&, False), (~, False), (Hospital, False), (es, False), (er, False), (., False), (oe, False), (SUMMARY, False), (., False), (~, False), (|, False), (AH, False), (4, False), (SS, False), (=, False), (=, False), (=, False), (|, False), (=, False), (=, False), (~, False), (|, False), (=, False), (‘, False), (cr, False), (|S, False), (|, False), (., False), (Albumin, False), (|, True), (|, False), (—, False), (=, False), (=, False)]\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.742\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=40] [doc 0] Token 0 '.' marked as sentence start (span begin)\u001b[0m\n",
            "\u001b[32m2026-01-11 05:38:36.746\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=40] Token/tag mapping: [(., True), (., False), (OS, False), (t, False), (-, False), (a., False), (-, False), (., False), (7, False), (t, False), (1, False), (a, False), (., False), (eS, False), (|, False), (:, False), (:, False), (:, False), (to, False), (hb, False), (Kory, False), (|, False), (4, False), (ho, False), (‘, False), (~, False), (qu, False), (Ce, False), (—, False), (|, False), (Te, False), (f, False), (=, False), (—, False), (:, False), (|, False), (t, False), (|, False), (oy, False), (ay, False), (|, False), (|, False), (a, False), (lg, False), (\\, False), (No, False), (7, False), (:, False), (:, False), (r, False), (1, False), (., False), (\\, False), (=, False), (., False), (:, False), (Poot, False), (Now, False), (:, False), (Date, False), (of, False), (., False), (|, False), (—, False), (—, False), (—, False), (~, False), (\\, False), (|, False), (J, False), (i, False), (AY, False), (., False), (~, False), (a, False), (on, False), (t, False), ({, False), (Times, False), (:, False), (2, False), (i, False), (Type, False), (6f, False), (Ad, False), (Discharge, False), (’, False), (:, False), (., False), (Le, False), (|, False), (., False), (“, False), (Ti, False), (—, False), (=, False), (fie, False), (|, False), (1, False), (=, False), (Th, False), (., False), (., False), (_, False), (1, False), (:, False), (=, False), (adr, False), (‘, False), (|, False), (Consultant, False), (Doctor, False), ('s, False), (Signature, False), (,, False), (Co, False), (», False), (o, False), (>, False), (a, False), (1, False), (~, False), (“, False), (h, False), (|, False), (be, False), (;, False), (LEY, False), (ow, False), (!, False), (:, False), (HO, False), (:, False), (Signature, False), (~, False), (¢, False), (:, False), (St, False), (i, False), (‘, False), (‘, False), (Staff, False), (Signature, False), (:, False), (*, False), (f, False), (*, False), («, False), (abe, False), (me, False), (con, False), (‘, False), (GOL, False), (of, False)]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[\"entities\"] = list(set(output[\"entities\"]))\n",
        "\n",
        "with open(\"ehr_extracted.json\", \"w\") as f:\n",
        "    json.dump(output, f, indent=4)\n",
        "\n",
        "print(\"✅ Extraction complete. File saved as ehr_extracted.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1yqaVDvjtqh",
        "outputId": "217ac2b5-49fa-4c8e-d4c6-9cf34322fc68"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction complete. File saved as ehr_extracted.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_1",
        "outputId": "ab4745b8-b2c1-49fe-8e41-91c15784684b"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(\"ehr_extracted.json\", \"r\") as f:\n",
        "    extracted_data = json.load(f)\n",
        "\n",
        "print(json.dumps(extracted_data, indent=4))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"patient\": {},\n",
            "    \"entities\": [],\n",
            "    \"pages\": [\n",
            "        {\n",
            "            \"page\": \"page_1\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_2\",\n",
            "            \"category\": \"labs\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_3\",\n",
            "            \"category\": \"discharge\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_4\",\n",
            "            \"category\": \"medications\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_5\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_6\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_7\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_8\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_9\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_10\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_11\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_12\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_13\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_14\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_15\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_16\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_17\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_18\",\n",
            "            \"category\": \"other\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_19\",\n",
            "            \"category\": \"discharge\"\n",
            "        },\n",
            "        {\n",
            "            \"page\": \"page_20\",\n",
            "            \"category\": \"labs\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "    text = text.replace(\"|\", \" \")\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"(hospital|medical college|road|phone|coimbatore)\", \"\", text, flags=re.I)\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "YHrCvhYOljE-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = normalize_text(text)\n"
      ],
      "metadata": {
        "id": "QW3Z5n0ilmty"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROCEDURE_MAP = {\n",
        "    \"debridement\": \"Wound debridement\",\n",
        "    \"incision\": \"Incision and drainage\",\n",
        "    \"drainage\": \"Incision and drainage\",\n",
        "    \"surgery\": \"Surgical procedure\",\n",
        "    \"operated\": \"Surgical procedure\",\n",
        "    \"suturing\": \"Wound suturing\",\n",
        "    \"dressing\": \"Wound dressing\",\n",
        "}\n"
      ],
      "metadata": {
        "id": "DAkzhyWPlm3S"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common clinical procedure keywords\n",
        "PROCEDURE_KEYWORDS = [\n",
        "    \"surgery\", \"surgical\", \"operation\", \"operated\",\n",
        "    \"debridement\", \"incision\", \"drainage\",\n",
        "    \"suturing\", \"dressing\", \"amputation\",\n",
        "    \"catheterization\", \"biopsy\"\n",
        "]\n",
        "\n",
        "# Investigation keywords\n",
        "INVESTIGATION_KEYWORDS = [\n",
        "    \"hb\", \"wbc\", \"rbc\", \"platelet\",\n",
        "    \"x-ray\", \"ct\", \"mri\", \"usg\", \"ultrasound\",\n",
        "    \"ecg\", \"echo\", \"blood sugar\", \"creatinine\"\n",
        "]\n",
        "\n",
        "# Medication indicators\n",
        "MED_PREFIX = [\"tab\", \"inj\", \"syp\", \"cap\", \"ointment\", \"cream\"]\n"
      ],
      "metadata": {
        "id": "ALkXC-Wik_vn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_procedures(text):\n",
        "    found = set()\n",
        "    lower = text.lower()\n",
        "\n",
        "    for key, label in PROCEDURE_MAP.items():\n",
        "        if key in lower:\n",
        "            found.add(label)\n",
        "\n",
        "    return list(found)\n",
        "\n"
      ],
      "metadata": {
        "id": "T0a9LFOulCOy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_investigations(text):\n",
        "    investigations = set()\n",
        "    lower_text = text.lower()\n",
        "\n",
        "    for test in INVESTIGATION_KEYWORDS:\n",
        "        if test in lower_text:\n",
        "            investigations.add(test.upper())\n",
        "\n",
        "    return list(investigations)\n"
      ],
      "metadata": {
        "id": "mkAIxrE4lEHu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_medications(text):\n",
        "    medications = []\n",
        "\n",
        "    lines = re.split(r\"\\n|,\", text)\n",
        "\n",
        "    for line in lines:\n",
        "        line_lower = line.lower()\n",
        "        for prefix in MED_PREFIX:\n",
        "            if line_lower.strip().startswith(prefix):\n",
        "                med = {}\n",
        "\n",
        "                med[\"raw_text\"] = line.strip()\n",
        "\n",
        "                # Drug name\n",
        "                name_match = re.search(r\"(tab|inj|cap|syp)\\s+([a-zA-Z]+)\", line_lower)\n",
        "                if name_match:\n",
        "                    med[\"drug_name\"] = name_match.group(2).title()\n",
        "\n",
        "                # Dose\n",
        "                dose_match = re.search(r\"(\\d+\\s*(mg|ml))\", line_lower)\n",
        "                if dose_match:\n",
        "                    med[\"dose\"] = dose_match.group(1)\n",
        "\n",
        "                # Frequency\n",
        "                freq_match = re.search(r\"(bd|tid|od|hs)\", line_lower)\n",
        "                if freq_match:\n",
        "                    med[\"frequency\"] = freq_match.group(1).upper()\n",
        "\n",
        "                medications.append(med)\n",
        "\n",
        "    return medications\n"
      ],
      "metadata": {
        "id": "oIAmN6sBlGXn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MED_REGEX = re.compile(r\"(tab|inj|cap|syp|ointment|cream)\\s+([a-zA-Z]+(?:\\s+[a-zA-Z]+)*)(?:\\s+(\\d+(?:\\.\\d+)?\\s*(?:mg|ml|units)))?(?:.*?(bd|tid|od|hs|q\\d+h))?\")\n",
        "\n",
        "def extract_medications(text):\n",
        "    meds = []\n",
        "\n",
        "    for match in MED_REGEX.finditer(text):\n",
        "        med = {\n",
        "            \"form\": match.group(1).upper(),\n",
        "            \"drug_name\": match.group(2).title(),\n",
        "            \"dose\": match.group(3) if match.group(3) else None,\n",
        "            \"frequency\": match.group(5).upper() if match.group(5) else None\n",
        "        }\n",
        "        meds.append(med)\n",
        "\n",
        "    return meds"
      ],
      "metadata": {
        "id": "5596hjLTl5WC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_output = {\n",
        "    \"patient\": {},\n",
        "    \"procedures\": [],\n",
        "    \"medications\": [],\n",
        "    \"investigations\": [],\n",
        "    \"page_summary\": []\n",
        "}\n",
        "\n",
        "for page, text in page_texts.items():\n",
        "    category = classify_page(text)\n",
        "\n",
        "    if category == \"demographics\":\n",
        "        final_output[\"patient\"].update(extract_patient_info(text))\n",
        "\n",
        "    if category in [\"discharge\", \"other\"]:\n",
        "        final_output[\"procedures\"].extend(extract_procedures(text))\n",
        "\n",
        "    if category == \"medications\":\n",
        "        final_output[\"medications\"].extend(extract_medications(text))\n",
        "\n",
        "    final_output[\"investigations\"].extend(extract_investigations(text))\n",
        "\n",
        "    final_output[\"page_summary\"].append({\n",
        "        \"page\": page,\n",
        "        \"category\": category\n",
        "    })\n"
      ],
      "metadata": {
        "id": "nTynXufClIf8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_output = {\n",
        "    \"patient\": {},\n",
        "    \"procedures\": [],\n",
        "    \"medications\": [],\n",
        "    \"investigations\": [],\n",
        "    \"page_summary\": []\n",
        "}\n",
        "\n",
        "for page, text in page_texts.items():\n",
        "    text = normalize_text(text)\n",
        "    category = classify_page(text)\n",
        "\n",
        "    if category == \"demographics\":\n",
        "        final_output[\"patient\"].update(extract_patient_info(text))\n",
        "\n",
        "    final_output[\"procedures\"].extend(extract_procedures(text))\n",
        "    final_output[\"medications\"].extend(extract_medications(text))\n",
        "    final_output[\"investigations\"].extend(extract_investigations(text))\n",
        "\n",
        "    final_output[\"page_summary\"].append({\n",
        "        \"page\": page,\n",
        "        \"category\": category\n",
        "    })\n",
        "\n",
        "# Deduplicate\n",
        "final_output[\"procedures\"] = list(set(final_output[\"procedures\"]))\n",
        "final_output[\"investigations\"] = list(set(final_output[\"investigations\"]))"
      ],
      "metadata": {
        "id": "-UvNLu-7l-XW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_output[\"procedures\"] = list(set(final_output[\"procedures\"]))\n",
        "final_output[\"investigations\"] = list(set(final_output[\"investigations\"]))\n",
        "\n",
        "with open(\"ehr_clinical_insights.json\", \"w\") as f:\n",
        "    json.dump(final_output, f, indent=4)\n",
        "\n",
        "print(\"✅ Clinical insights extracted successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gs6FFfSlLOq",
        "outputId": "286d5d83-745d-4141-ff07-1c0f1606e3d5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Clinical insights extracted successfully\n"
          ]
        }
      ]
    }
  ]
}